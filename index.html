<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="stylesheet" href="styles.css">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Perceptron</title>
</head>
<body background="img/wallpaper.jpg">
    <header>
        <h1>Персептрон</h1>
    </header>
    <main>
        <p class="text"><b>Персептрон</b> – это нейронная сеть, которая 
		представляет собой алгоритм для выполнения двоичной классификации.
		Он определяет, относится ли объект к определенной категории 
		(например, является ли животное на рисунке кошкой или нет).
        </p>
		
		<img src="img/perceptron.bmp">
		
		<h2>Как работает персептрон</h2>

        <p class="text">Персептроны часто применяются 
		для решения контролируемых задач обучения: 
		они тренируются по набору пар входных/выходных 
		объектов и учатся моделировать корреляции (
		т. е. зависимости) между этими данными. 
		Обучение включает в себя настройку параметров
		модели (весовых коэффициентов, смещений) для 
		минимизации погрешности. Для корректировки этих 
		параметров относительно погрешности используется
		алгоритм обратного распространения, а сама 
		погрешность может быть вычислена различными 
		способами, в том числе путем вычисления 
		среднеквадратичного отклонения (RMSE).
		
		<p>Сети прямого распространения, 
		такие как многослойный персептрон, похожи на теннис или пинг-понг.
		Они в основном состоят из двух видов движений: вперед и назад. 
		Получается своеобразная игра в пинг-понг между догадками и ответами,
		поскольку каждая догадка – это проверка того, что мы знаем, 
		а каждый ответ – это обратная связь, позволяющая нам узнать,
		насколько сильно мы ошибаемся.</p>
		
		<p>При шаге вперед поток 
		сигнала перемещается от входного слоя через скрытые 
		к выходному, а решение, полученное на выходном слое, 
		сравнивается с априорно известным верным ответом.</p>
		
		<p>При шаге назад с использованием правила дифференцирования 
		сложных функций через персептрон в обратном направлении 
		распространяются частные производные функции, погрешности 
		по весовым коэффициентам и смещениям. Данный акт 
		дифференцирования дает нам градиент погрешности, 
		с использованием которого могут быть скорректированы 
		параметры модели, так как они приближают МП на один 
		шаг ближе к минимуму погрешности. Это можно сделать
		с помощью любого алгоритма градиентной оптимизации, 
		например, методом стохастического градиентного спуска. 
		Сеть продолжает играть в пинг-понг, пока погрешность 
		не исчезнет. В этом случае, как говорят, наступает сходимость.
		</p>
		
		<p><a href="https://cataxex.github.io/Pascal/">Посетить сайт "Паскаль"</a></p>
	    	<p><a href="https://cataxex.github.io/C-/">Посетить сайт "C#"</a></p>
		
		<h3>Источьники:<h3>
		<a href="https://neurohive.io/ru/osnovy-data-science/perseptron-rozenblatta-mashina-kotoraja-smogla-obuchatsja/#:~:text=Персептрон%20–%20это%20нейронная%20сеть%2C,на%20рисунке%20кошкой%20или%20нет)">Персептрон Розенблатта</a>
    </main>
</body>
</html>
